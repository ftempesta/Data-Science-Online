{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial 2: Clasificación",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ftempesta/Data-Science-Online/blob/master/Tutorial_2_Clasificaci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzT4qudB72Fl"
      },
      "source": [
        "# Tutorial 2: Clasificación\n",
        "\n",
        "6 de mayo de 2021\n",
        "\n",
        "1. Crea una copia de este notebook\n",
        "2. Sigue las instrucciones del notebook y ejecuta los bloques de código en el orden en que aparecen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDytw3uMerxH"
      },
      "source": [
        "## Preámbulo\n",
        "\n",
        "Las celdas de código en este notebook sólo aceptan código en Python, pero hay ciertas \"palabras clave\" que permiten hacer otras cosas. Por ejemplo, con `!` podemos llamar a un comando del sistema.\n",
        "\n",
        "En este caso, vamos a llamar a `pip` (Package Installer for Python) para instalar las librerías que vamos a usar en este laboratorio. \n",
        "\n",
        "Haz click en la celda para seleccionarla y luego presiona **Ctrl+Enter** o **Shift+Enter** para ejecutarla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQMngX5l79Gf"
      },
      "source": [
        "!pip install scikit-learn pandas numpy matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJd3AwpwUdcM"
      },
      "source": [
        "## Cargar datos\n",
        "\n",
        "Usaremos el dataset _iris_ disponible en scikit-learn.\n",
        "\n",
        "![iris dataset](https://sebastianraschka.com/images/blog/2014/intro_supervised_learning/iris_petal_sepal_1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1GUGl598T2u"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "# la variable iris es un objeto con varios atributos\n",
        "# podemos verlos escribiendo \"iris.\" y luego TAB para que Colab nos muestre las \n",
        "# posibles completaciones\n",
        "\n",
        "# mostramos las primeras 10 filas\n",
        "iris.data[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVWiXhUS92XJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be594661-61c0-4dc8-dec8-0a533113af74"
      },
      "source": [
        "# listamos los atributos\n",
        "\n",
        "iris.feature_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzf0HSc1Uvvg"
      },
      "source": [
        "# listamos las clases (10 primeras filas)\n",
        "\n",
        "iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYy9zgNwVDVQ"
      },
      "source": [
        "# target_names son los nombres de las clases\n",
        "# clase 0 corresponde a 'setosa'\n",
        "# clase 1 corresponde a 'versicolor'\n",
        "# clase 2 corresponde a 'virginica'\n",
        "\n",
        "iris.target_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8c35cGOWteq"
      },
      "source": [
        "Usando la librería `pandas` para manipular datos podemos generar una vista más \"agradable\" de los datos:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUjHad0VWalo"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df['clase'] = iris.target_names[iris.target]\n",
        "\n",
        "# df.sample muestrea n=10 filas\n",
        "df.sample(n=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQofZO95acN4"
      },
      "source": [
        "Podemos visualizar los datos usando una _scatterplot matrix_ (o matriz de dispersión) para ver cómo se\n",
        "comportan los atributos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqn2-DUaaejN"
      },
      "source": [
        "fig = pd.plotting.scatter_matrix(df, figsize=(10, 10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7m4Bfo6Vabg"
      },
      "source": [
        "Una notación estándar es llamar $X$ a la matriz que contiene a los datos e $y$ al vector que contiene el valor de la clase para cada fila en $X$. \n",
        "\n",
        "Es decir, $X$ tiene $N$ filas y $p$ columnas (donde $p$ es la cantidad de atributos) e $y$ es un vector de $N$ valores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpfDOZDGVGF_"
      },
      "source": [
        "# nos referiremos con 'X' a los datos y con 'y' a las clases\n",
        "# nota que ambas son variables numéricas\n",
        "# X es una 'matriz' (es una lista de listas de valores asociados a atributos)\n",
        "# y es un vector (una lista de valores)\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6329Zb03Fpy"
      },
      "source": [
        "## Separar datos en train y test\n",
        "\n",
        "**IMPORTANTE**: En este punto debemos crear nuestros conjuntos de entrenamiento y de test.\n",
        "\n",
        "Tenemos dos opciones:\n",
        "\n",
        "1. Hacemos un *muestreo aleatorio* de los datos para separarlos en train y test.\n",
        "2. Hacemos un *muestreo *estratificado* con respecto a la clase. Es decir, nos aseguramos que tanto train y test tengan la misma distribución de clases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR7Uubpi3QzR"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# al dejar `random_state` con un valor fijo nos garantiza que\n",
        "# bajo las mismas condiciones, los resultados serán los mismos\n",
        "# En este caso, la partición será la misma al ejecutar este bloque\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paGUdOEG36o1"
      },
      "source": [
        "# Baseline\n",
        "\n",
        "Lo primero que debemos considerar antes de entrenar o decidir con cuál modelo nos vamos a quedar es cuál es el \"piso mínimo\" que podemos esperar.\n",
        "\n",
        "Un *baseline* es un modelo simple, básico, que incluso puede no aprender nada de los datos, pero que nos sirve para saber cuál es el rendimiento mínimo que podemos alcanzar con los datos.\n",
        "\n",
        "En el siguiente código vamos a declarar un algoritmo de aprendizaje \"dummy\" o \"tonto\". En este caso, el modelo entrenado va a predecir cualquiera de las tres clases al azar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAfBhx4Q4o_f"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# declaramos el modelo dummy\n",
        "# hasta ahora no hemos hecho nada con los datos\n",
        "dc = DummyClassifier(strategy=\"uniform\", random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBaZaMiO5Qdn"
      },
      "source": [
        "Ahora entrenamos un modelo. **IMPORTANTE**: El modelo se entrena con los datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksp0MjZu5P_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836e0dcc-975a-4144-d083-678898618f02"
      },
      "source": [
        "# este método altera el modelo\n",
        "dc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DummyClassifier(constant=None, random_state=42, strategy='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1avpltdY5PUH"
      },
      "source": [
        "Ahora vemos cómo le fue a este modelo con los datos de test.\n",
        "\n",
        "Le vamos a pasar los datos de prueba al modelo, el cual entregará una _predicción_ por cada uno de las filas de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSlkLq795rXq"
      },
      "source": [
        "y_pred = dc.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUorpk9x5uif"
      },
      "source": [
        "Finalmente comparamos el resultado de la predicción, `y_pred` con la respuesta correcta, `y_test`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZT6tExx6kyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce22a0c7-1cca-4db4-b3b9-b09c4971b3ec"
      },
      "source": [
        "# podemos ver el accuracy, precision, recall por cada clase\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# (ver https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin\n",
        "# diferencia entre macro y micro average)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.19      0.19        16\n",
            "           1       0.27      0.24      0.25        17\n",
            "           2       0.20      0.24      0.22        17\n",
            "\n",
            "    accuracy                           0.22        50\n",
            "   macro avg       0.22      0.22      0.22        50\n",
            "weighted avg       0.22      0.22      0.22        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4hLyFIO7LeW"
      },
      "source": [
        "Se observa que el accuracy es aproximadamente $0.22$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k736Dk1X7noa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR92ZKOdVwvV"
      },
      "source": [
        "# Entrenar un modelo\n",
        "\n",
        "Entrenaremos un árbol de decisión con los datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bfby42qVupz"
      },
      "source": [
        "from sklearn import tree\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(random_state=42, criterion='entropy')\n",
        "clf = clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHp8_QIgWJkx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0743ffb8-3b54-4383-e09d-5c27782880f6"
      },
      "source": [
        "# vemos cómo le fue\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       0.83      0.88      0.86        17\n",
            "           2       0.88      0.82      0.85        17\n",
            "\n",
            "    accuracy                           0.90        50\n",
            "   macro avg       0.90      0.90      0.90        50\n",
            "weighted avg       0.90      0.90      0.90        50\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veD33OOXbCgM"
      },
      "source": [
        "Bastante mejor que al baseline.\n",
        "\n",
        "Podemos ver el árbol resultante:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIR3TK6GmJje"
      },
      "source": [
        "import pydotplus \n",
        "from IPython.display import Image\n",
        "\n",
        "dot_data = tree.export_graphviz(clf, \n",
        "                                feature_names=iris.feature_names, \n",
        "                                class_names=iris.target_names, \n",
        "                                filled=True, \n",
        "                                out_file=None) \n",
        "\n",
        "graph = pydotplus.graph_from_dot_data(dot_data) \n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTupmWbGeWTa"
      },
      "source": [
        "# Estimar el error fuera de la muestra\n",
        "\n",
        "Arriba usamos holdout (separar los datos en train y test) para evaluar el clasificador. \n",
        "\n",
        "Recuerda que un problema de holdout es que podemos tener buena o mala suerte y elegir una muestra muy particular cuando tenemos pocos datos.\n",
        "\n",
        "Por ejemplo, ¿qué pasa si elegimos otra partición train/test?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUPQtA-u-8v-"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=7, stratify=y)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(random_state=42)\n",
        "clf = clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EA8Shzm_znf"
      },
      "source": [
        "Podemos ver que bajamos de un 95% a un 92% de accuracy. No es mucho, pero ilustra cómo puede cambiar el resultado si cambiamos la muestra.\n",
        "\n",
        "Una forma más consistente de determinar el error fuera de la muestra es usando cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2VmEVfw-yJt"
      },
      "source": [
        "## Cross-validation\n",
        "\n",
        "Recuerda que CV divide los datos en $k$ partes iguales: entrena con $k-1$ partes y evalúa con la parte restante, y esto lo repite $k$ veces (una vez por cada parte a evaluar).\n",
        "Esta técnica se conoce como $k$-folds cross-validation.\n",
        "\n",
        "Vamos a hacer cross-validation de forma \"manual\" para ver cómo se comporta.\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/1/1c/K-fold_cross_validation_EN.jpg)\n",
        "\n",
        "\n",
        "**NOTA**: Recuerda que CV puede usarse para dos propósitos muy relacionados entre sí:\n",
        "\n",
        "1. Tener una estimación del error fuera de la muestra (error de test), como haremos en este ejemplo (en este ejemplo usamos todo `X` e `y`).\n",
        "\n",
        "2. Elegir un modelo o ajustar parámetros de éste (para eso usamos `X_train` e `y_train`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwIKhOvdd_dg"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# este código tiene un problema!\n",
        "\n",
        "# 5-fold cv\n",
        "kf = KFold(n_splits=5)\n",
        "\n",
        "accuracies = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index, sep='\\n')\n",
        "    print()\n",
        "    \n",
        "    X_train = X[train_index]\n",
        "    X_test = X[test_index]\n",
        "    \n",
        "    y_train = y[train_index]\n",
        "    y_test = y[test_index]\n",
        "\n",
        "    clf = tree.DecisionTreeClassifier(random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = clf.predict(X_test)\n",
        "    \n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "print()\n",
        "print(\"Accuracy de cada fold:\", accuracies)\n",
        "print(\"Accuracy promedio: \", sum(accuracies) / len(accuracies))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A1XLUBgAa7f"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPyY69c0hl_T"
      },
      "source": [
        "## Medidas de evaluación\n",
        "\n",
        "¿Qué pasa cuando tenemos clases desbalanceadas? Por ejemplo, si tenemos dos clases, y están en relación 9:1, ¿puede pensar en un clasificador que tenga al menos 90% de accuracy?\n",
        "\n",
        "Podemos hacer un análisis más fino del rendimiento por clase usando más medidas de evaluación. Entre las más importantes se cuentan **Precision** y **Recall** (o Recuperación).\n",
        "\n",
        "$$Precision = \\frac{TP}{TP + FP}$$\n",
        "\n",
        "$$Recall = \\frac{TP}{TP+FN}$$\n",
        "\n",
        "Nota que estas medidas son para una clase en particular. La medida para todo el dataset puede ser el promedio de la medida para cada clase.\n",
        "\n",
        "Supongamos que tenemos varias clases, pero nos queremos enfocar en una en particular, digamos $c$:\n",
        "\n",
        "- $TP$ corresponde a los True Positive, o Verdaderos Positivos, es decir, los aciertos del clasificador: cuando clasificamos una observación correctamente como $c$.\n",
        "- $FP$, o False Positive, es cuando clasificamos incorrectamente una observación como $c$, cuando en verdad no lo era.\n",
        "- $TN$, o True Negative, cuando clasificamos correctamente algo que no es $c$\n",
        "- $FN$, False Negative, cuando clasificamos incorrectamente algo que no es $c$\n",
        "\n",
        "\n",
        "Otra forma de entender Precision y Recall al clasificar una clase $c$ es como sigue: \n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{Precision}_c = \\frac{\\text{#(observations correctly classified as } c \\text{)}}{ \\text{#(observations classified as } c \\text{)} }\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "    \\text{Recall}_c = \\frac{\\text{#(observations correctly classified as } c \\text{)}}{ \\text{#(observations of class } c\\text{)} } \n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "Adicionalmente defimos la _matriz de confusión_ para observar los errores del clasificador:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp3R5uwolG_B"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=54)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(random_state=54)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fdoLMlalL47"
      },
      "source": [
        "La matriz se interpeta de la siguiente forma:\n",
        "\n",
        "| iris-setosa  | iris-versicolor  | iris-virginica  | ← clasificado como / clase real ↓ |\n",
        "|:----:|:----:|:----:|--------------------:|\n",
        "| 12 | 0  | 0  |              **iris-setosa** |\n",
        "| 0  | 17  | 1  |              **iris-versicolor** |\n",
        "| 0  | 2 | 18 |              **iris-virginica** |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0qp8lxWn0K2"
      },
      "source": [
        "# Overfitting\n",
        "\n",
        "El objetivo de un clasificador es poder aprender lo más que pueda de los datos, y al mismo tiempo poder **generalizar** su \"conocimiento\" a datos nuevos que nunca ha visto. \n",
        "\n",
        "El _overfitting_ se produce cuando el clasificador pierde la capacidad de generalización. Esto se observa usualmente cuando el clasificador se _sobreajusta_ a los datos, impidiendo que pueda predecir correctamente datos nuevos que nunca ha visto.\n",
        "\n",
        "Otro problema con el overfitting es que nos dificulta tener una buena estimación del error de un clasificador. Por ejemplo, ¿qué pasa si quiero estimar parámetros de un clasificador usando el conjunto de prueba?\n",
        "\n",
        "¿En qué otros casos se produce este problema de estimación?\n",
        "\n",
        "\n",
        "El ejemplo abajo ilustra el sobreajuste al conjunto de entrenamiento, impidiendo al clasificador generalizar a datos nuevos (a la función objetivo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2KcUBUnoeGj"
      },
      "source": [
        "# ejemplo obtenido de http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "def true_fun(X):\n",
        "    return np.cos(1.5 * np.pi * X)\n",
        "\n",
        "n_samples = 30\n",
        "degrees = [1, 4, 15]\n",
        "\n",
        "X = np.sort(np.random.rand(n_samples))\n",
        "y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
        "\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "for i in range(len(degrees)):\n",
        "    ax = plt.subplot(1, len(degrees), i + 1)\n",
        "    plt.setp(ax, xticks=(), yticks=())\n",
        "\n",
        "    polynomial_features = PolynomialFeatures(degree=degrees[i],\n",
        "                                             include_bias=False)\n",
        "    linear_regression = LinearRegression()\n",
        "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
        "                         (\"linear_regression\", linear_regression)])\n",
        "    pipeline.fit(X[:, np.newaxis], y)\n",
        "\n",
        "    # Evaluate the models using crossvalidation\n",
        "    scores = cross_val_score(pipeline, X[:, np.newaxis], y,\n",
        "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
        "\n",
        "    X_test = np.linspace(0, 1, 100)\n",
        "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label=\"Model\")\n",
        "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
        "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.xlim((0, 1))\n",
        "    plt.ylim((-2, 2))\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(\n",
        "        degrees[i], -scores.mean(), scores.std()))\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiX1lgR0mJro"
      },
      "source": [
        "# En conclusión\n",
        "\n",
        "El flujo usual a la hora de entrenar un clasificador es el siguiente:\n",
        "\n",
        "1. Tener datos. Verificar la fuente de los datos, la existencia de sesgos.\n",
        "2. Separar datos en train y test set.\n",
        "3. Realizar preprocesamiento y limpieza de datos en ambos sets, **de manera independiente**.\n",
        "4. Determinar hiperparámetros del clasificador usando un conjunto de validación (holdout) o usando cross-validation.\n",
        "5. Evaluar en el test set para tener una estimación del rendimiento real del clasificador.\n",
        "6. Para el modelo final, usar todos los datos disponibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL8HRYDyf4UB"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "1. Tutorial scikit-learn de árboles de decisión. https://scikit-learn.org/stable/modules/tree.html#classification\n",
        "1. Documentación de scikit-learn. http://scikit-learn.org/stable/index.html\n",
        "2. Precision y Recall. https://en.wikipedia.org/wiki/Precision_and_recall\n",
        "3. Machine Learning 101 (Google). https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/preview?imm_mid=0f9b7e&cmp=em-data-na-na-newsltr_20171213#slide=id.g168a3288f7_0_58\n",
        "4. WEKA (un programa visual con clasificadores y otras herramientas para ML). https://www.cs.waikato.ac.nz/ml/weka/\n",
        "5. Curso de Data Mining con WEKA. https://www.cs.waikato.ac.nz/ml/weka/mooc/dataminingwithweka/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NN_X7KPf4_W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}